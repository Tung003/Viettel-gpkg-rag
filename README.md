<p align="center">
 <h1 align="center">LLM Q&A about Viettel telecom package information</h1>
</p>

[![GitHub license](https://img.shields.io/github/license/Tung003/LLM-Q-A)](https://github.com/Tung003/LLM-Q-A/blob/main/LICENSE)

## Introduction

Here is my python source code for LLM Question and Answer about Viettel telecom package information:

* Run a Web applications that are publicly accessible via domain name or IP.
* RAG (Retrieval Augmented Generation) with custom dataset.
* Deploy on AWS free (EC2) with FastAPI.
* The model used: https://huggingface.co/nguyenvulebinh/vi-mrc-large

## Web app
<p align="justify">
Due to the lack of powerful hardware and a limited budget for renting high-performance machines on AWS, using small and lightweight models for deployment is a practical choice. However, this comes with the trade-off of slightly lower performance or quality.
</p>

<p align="justify">
However, if you have access to more powerful hardware or want to experiment with higher-performance models, you can try using larger ones like https://huggingface.co/vilm/vinallama-2.7b-chat. I‚Äôve also included support for this model in the following section.
</p>

<p align="center">
  <img src="Screencastfrom2025-07-2813-54-15-ezgif.com-video-to-gif-converter(1).gif" width="100%"><br/>
  <i>Web app demo</i>
</p>

## Test vinallama-2.7b-chat

In this test, the model in normal mode returns the full response only after the entire output has been generated. [‚ú® vinallama-2.7b-chat notebook](./RAG_answer_package_infor.ipynb)


<p align="justify">
To run this model you need to have the appropriate hardware such as T4 GPU or A100 GPU from Google Colab
</p>

<table align="center">
  <tr>
    <td align="center" width="45%">
      <img src="img_result/Screenshot from 2025-07-28 15-33-51.png" width="100%"><br>
    </td>
    <td align="center" width="45%">
      <img src="img_result/Screenshot from 2025-07-28 15-32-55.png" width="100%"><br>
    </td>
  </tr>
</table>
<p align="center"><em>Test vinallama 2.7b chat</em></p>

In contrast, in streaming mode, the model outputs words in real-time, displaying them immediately as they are generated.  [üöÄ vinallama-2.7b-chat stream](./RAG_module_stream.py)

<p align="center">
  <img src="img_result/streaming.gif" width="100%"><br/>
  <i>Web app demo</i>
</p>

<p align="center"><em>Test vinallama 2.7b chat mode stream</em></p>

## Dataset
The dataset crawl by BeautifulSoup and Selenium and Data is saved in json file with the following structure:
```json
{
  "text": "information package",
  "metadata": {
    "url": "url package",
    "title": "name package"
  }
}

```
Then convert the data into structured formats to make it easier for embedding into the vector store and retrieving from it.

Such as:
```json
{
    "conversations": [
      {
        "role": "user",
        "content": "T√¥i mu·ªën bi·∫øt th√¥ng tin v·ªÅ g√≥i c∆∞·ªõc ST70K?"
      },
      {
        "role": "assistant",
        "content": "Th√¥ng tin c·ªßa g√≥i c∆∞·ªõc ST70K:\nT√™n g√≥i c∆∞·ªõc: ST70K chi ti·∫øt:\n∆Øu ƒë√£i\nGi√° c∆∞·ªõc:\n 70.000ƒë\n(ƒê·ªëi v·ªõi thu√™ bao tr·∫£ sau: ƒêƒÉng k√Ω t·ª´ ng√†y 21 ƒë·∫øn cu·ªëi th√°ng s·∫Ω gi·∫£m 50% ph√≠ g√≥i v√† c√≥ 500MB/ng√†y)\n∆Øu ƒë√£i:\n- 500MB data t·ªëc ƒë·ªô cao/ng√†y, h·∫øt l∆∞u l∆∞·ª£ng ng·ª´ng truy c·∫≠p.\n- G√≥i c∆∞·ªõc t·ª± ƒë·ªông gia h·∫°n khi h·∫øt chu k·ª≥ (Kh√¥ng b·∫£o l∆∞u data khi gia h·∫°n th√†nh c√¥ng)\n- ∆Øu ƒë√£i s·ª≠ d·ª•ng trong 30 ng√†y (tr·∫£ tr∆∞·ªõc), h·∫øt th√°ng (tr·∫£ sau).\nƒêƒÉng k√Ω: \nB·∫•m ƒêƒÉng k√Ω, so·∫°n ST70K g·ª≠i 191, b·∫•m g·ªçi *098*174#.\nH·ªßy gia h·∫°n\n: B·∫•m \"H·ªßy\" ho·∫∑c so·∫°n HUY g·ª≠i 191.\nH·ªßy g√≥i: \nSo·∫°n tin HUYDATA g·ª≠i 191. \nN·∫øu c·∫ßn chi ti·∫øt h∆°n b·∫°n c√≥ th·ªÉ v√†o trang web ch√≠nh th·ª©c c·ªßa Viettel bi·∫øt th√™m th√¥ng tin :https://viettel.vn/vx/di-dong/goi-data/ST70K"
      }
    ]
  }
```
Or:
```json
{
    "text": "G√≥i c∆∞·ªõc gia h·∫°n sau 180 ng√†y",
    "metadata": {
      "url": "https://viettel.vn/vx/di-dong/goi-data/6M10_100M",
      "title": "6M10_100M",
      "section": "Gia h·∫°n"
    }
  }
```
